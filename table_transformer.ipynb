{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Data processing and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score,confusion_matrix, f1_score, recall_score, ConfusionMatrixDisplay\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "# Image processing and OCR\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Transformers and huggingface_hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import DetrFeatureExtractor, TableTransformerForObjectDetection\n",
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "\n",
    "# PyTorch\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Working Directory and Program Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Get parent directory\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "\n",
    "DATA_PATH = parent_dir ## Path To Repository \n",
    "TESSERACT_PATH = r'C:/Program Files/Tesseract-OCR/tesseract' ## Path To Tesseract OCR - See README For Setup \n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "test_labels = pd.read_csv(os.path.join(DATA_PATH, 'Capstone Project - Table Text Extraction/Labeled Data.csv'))\n",
    "test_labels['Pred'] = None\n",
    "\n",
    "# Set working directory\n",
    "working_directory = os.path.join(DATA_PATH, 'WAMEX_DATA_EXTRACTED')\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Set tesseract path\n",
    "pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH\n",
    "\n",
    "# List all files and get their full paths\n",
    "files = os.listdir()\n",
    "concatenated_paths = [os.path.join(working_directory, filename) for filename in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Table Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_EXTENSIONS = {'.jpg', '.png'}\n",
    "COLORS = [\n",
    "    [0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "    [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]\n",
    "]\n",
    "\n",
    "# Define Model and Feature Extractor\n",
    "feature_extractor = DetrFeatureExtractor()\n",
    "model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "# Functions\n",
    "def get_valid_images(directory):\n",
    "    \"\"\"Get valid image files from a directory.\"\"\"\n",
    "    all_files = [os.path.join(directory, file) for file in os.listdir(directory)\n",
    "                 if os.path.isfile(os.path.join(directory, file))\n",
    "                 and os.path.splitext(file)[1].lower() in VALID_EXTENSIONS]\n",
    "    return all_files\n",
    "\n",
    "\n",
    "def move_jpg_to_extracted_folder(directory):\n",
    "    \"\"\"Move all JPG files in a directory to a sub-directory named 'jpg_extracted'.\"\"\"\n",
    "    jpg_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.lower().endswith('.jpg')]\n",
    "    \n",
    "    # Create 'jpg_extracted' sub-directory if it doesn't exist\n",
    "    extracted_folder = os.path.join(directory, \"jpg_extracted\")\n",
    "    if not os.path.exists(extracted_folder):\n",
    "        os.makedirs(extracted_folder)\n",
    "\n",
    "    # Move each JPG file to the 'jpg_extracted' folder\n",
    "    for jpg_file in jpg_files:\n",
    "        shutil.move(os.path.join(directory, jpg_file), os.path.join(extracted_folder, jpg_file))\n",
    "\n",
    "\n",
    "\n",
    "def process_directory(directory, plot=False):\n",
    "    \"\"\"Process all valid images in a directory and return a DataFrame.\"\"\"\n",
    "    print(f\"Processing images in directory: {os.path.basename(directory)}\")\n",
    "    \n",
    "    all_files = get_valid_images(directory)\n",
    "    all_data = []\n",
    "    \n",
    "    for image_file in all_files:\n",
    "        data = process_image(image_file, base_save_path=directory, plot=plot)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "\n",
    "    # Move the JPG files to the 'jpg_extracted' folder after processing\n",
    "    move_jpg_to_extracted_folder(directory)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "def process_image(file_name, base_save_path, buffer=30, plot=True):\n",
    "    base_file_name = os.path.basename(file_name).rsplit('.', 1)[0]\n",
    "    file_parts = base_file_name.split('_')\n",
    "    \n",
    "    image = Image.open(file_name).convert(\"RGB\")\n",
    "    img_cv = cv2.imread(file_name)\n",
    "    width, height = image.size\n",
    "    encoding = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.94, target_sizes=[(height, width)])[0]\n",
    "    num_tables = len(results['scores'])\n",
    "\n",
    "    boxes = results['boxes'] # Direct extraction from results\n",
    "    if len(boxes) > 0:\n",
    "        specific_save_path = os.path.join(base_save_path, f\"{base_file_name} Cropped Images\")\n",
    "        if not os.path.exists(specific_save_path):\n",
    "            os.makedirs(specific_save_path)\n",
    "\n",
    "        for index, box in enumerate(boxes):\n",
    "            x1 = int(box[0])\n",
    "            y1 = int(box[1])\n",
    "            x2 = int(box[2])\n",
    "            y2 = int(box[3])\n",
    "            \n",
    "            # Adjust the buffer for x1 and x2 (wideness) by 1.2 times\n",
    "            x1 = max(0, x1 - int(1.2 * buffer))\n",
    "            y1 = max(0, y1 - buffer)\n",
    "            x2 = min(img_cv.shape[1], x2 + int(4.5 * buffer))\n",
    "            y2 = min(img_cv.shape[0], y2 + buffer)\n",
    "\n",
    "            \n",
    "            cropped_img = img_cv[y1:y2, x1:x2]\n",
    "            cv2.imwrite(f\"{specific_save_path}/{base_file_name}_table_{index}.png\", cropped_img)\n",
    "\n",
    "    if plot and num_tables > 0:\n",
    "        plot_results(image, results['scores'], results['labels'], results['boxes'])\n",
    "\n",
    "    if len(file_parts) == 2:\n",
    "        return {'FileName': file_parts[0], 'Page Number': file_parts[1], 'Number of tables': num_tables}\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def plot_results(pil_img, scores, labels, boxes):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    for score, label, (xmin, ymin, xmax, ymax),c  in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        text = f'{model.config.id2label[label]}: {score:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=15,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "all_data = []\n",
    "\n",
    "for path in concatenated_paths:\n",
    "    if os.path.isdir(path):\n",
    "        df = process_directory(path, plot=False)\n",
    "        all_data.append(df)\n",
    "    elif os.path.isfile(path) and os.path.splitext(path)[1].lower() in VALID_EXTENSIONS:\n",
    "        parent_dir = os.path.dirname(path)  # This is where our cropped images would be saved\n",
    "        data = process_image(path, base_save_path=parent_dir, plot=False)\n",
    "        if data:\n",
    "            all_data.append(pd.DataFrame([data]))\n",
    "\n",
    "# Concatenate all data into the master dataframe\n",
    "master_df = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Perform Table Data Extraction Using Morphological Operations Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Functions\n",
    "def find_subdirs_with_name(path, keyword):\n",
    "    \"\"\"Return all subdirectories containing the given keyword.\"\"\"\n",
    "    return [os.path.join(root, directory) for root, dirs, files in os.walk(path) for directory in dirs if keyword in directory]\n",
    "\n",
    "def find_image_files_in_dir(path):\n",
    "    \"\"\"Return all image files in the directory.\"\"\"\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff']\n",
    "    return [os.path.join(root, file) for root, dirs, files in os.walk(path) for file in files if any(file.lower().endswith(ext) for ext in image_extensions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    \n",
    "    img_bin = 255 - image\n",
    "    _, img_bin_otsu = cv2.threshold(img_bin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Vertical Line extraction\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, np.array(img_bin_otsu).shape[1]//150))\n",
    "    eroded_image = cv2.erode(img_bin_otsu, vertical_kernel, iterations=5)\n",
    "    vertical_lines = cv2.dilate(eroded_image, vertical_kernel, iterations=5)\n",
    "    \n",
    "    # Horizontal Line extraction\n",
    "    hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (np.array(img_bin_otsu).shape[1]//150, 1))\n",
    "    image_2 = cv2.erode(img_bin_otsu, hor_kernel, iterations=5)\n",
    "    horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=5)\n",
    "\n",
    "    # Combining\n",
    "    vertical_horizontal_lines = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    vertical_horizontal_lines = cv2.erode(~vertical_horizontal_lines, kernel, iterations=3)\n",
    "    _, vertical_horizontal_lines = cv2.threshold(vertical_horizontal_lines, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    b_image = cv2.bitwise_not(cv2.bitwise_xor(image, vertical_horizontal_lines))\n",
    "    return b_image, vertical_horizontal_lines\n",
    "\n",
    "\n",
    "def extract_bounding_boxes(b_image, vertical_horizontal_lines):\n",
    "    contours, _ = cv2.findContours(vertical_horizontal_lines, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boundingBoxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    (contours, boundingBoxes) = zip(*sorted(zip(contours, boundingBoxes), key=lambda x: x[1][1]))\n",
    "\n",
    "    boxes = []\n",
    "    image_copy = b_image.copy()  # Initialize image_copy here\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        x-=1\n",
    "        w+=1\n",
    "        if w < 1000 and h < 500:\n",
    "            cv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "            boxes.append([x, y, w, h])\n",
    "            \n",
    "    return boxes\n",
    "\n",
    "def extract_text_from_boxes(b_image, boxes):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    heights = [box[3] for box in boxes]  # Extracting the heights of all boxes\n",
    "    mean_height = np.mean(heights)\n",
    "\n",
    "    # Initialize columns list with the first box and set the previous box to the first box\n",
    "    columns.append(boxes[0])\n",
    "    previous_box = boxes[0]\n",
    "\n",
    "    for i in range(1, len(boxes)):\n",
    "        if boxes[i][1] <= previous_box[1] + mean_height / 2:\n",
    "            columns.append(boxes[i])\n",
    "            previous_box = boxes[i]\n",
    "            if i == len(boxes) - 1:\n",
    "                rows.append(columns)\n",
    "        else:\n",
    "            rows.append(columns)\n",
    "            columns = []\n",
    "            previous_box = boxes[i]\n",
    "            columns.append(boxes[i])\n",
    "\n",
    "    # Determine the total number of cells in the row with the maximum cells\n",
    "    total_cells = max([len(r) for r in rows])\n",
    "\n",
    "    # Find the center of each box in the first row\n",
    "    centers = [int(rows[0][j][0] + rows[0][j][2] / 2) for j in range(len(rows[0]))]\n",
    "    centers = np.array(centers)\n",
    "    centers.sort()\n",
    "\n",
    "    # Organize boxes by their closest center position\n",
    "    boxes_list = []\n",
    "    for i in range(len(rows)):\n",
    "        l = [[] for _ in range(total_cells)]\n",
    "        for j in range(len(rows[i])):\n",
    "            # Find the closest center for the current box\n",
    "            diff = abs(centers - (rows[i][j][0] + rows[i][j][2] / 4))\n",
    "            minimum = min(diff)\n",
    "            index = list(diff).index(minimum)\n",
    "            l[index].append(rows[i][j])\n",
    "        boxes_list.append(l)\n",
    "\n",
    "    # Extracting text from cells in the image\n",
    "    dataframe_final = []\n",
    "    for i in range(len(boxes_list)):\n",
    "        for j in range(len(boxes_list[i])):\n",
    "            s = ''\n",
    "            if len(boxes_list[i][j]) == 0:\n",
    "                dataframe_final.append(' ')\n",
    "            else:\n",
    "                for k in range(len(boxes_list[i][j])):\n",
    "                    x, y, w, h = boxes_list[i][j][k]\n",
    "                    roi = b_image[y:y+h, x:x+w]\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))\n",
    "                    border = cv2.copyMakeBorder(roi, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=[255, 255])\n",
    "                    resizing = cv2.resize(border, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "                    dilation = cv2.dilate(resizing, kernel, iterations=1)\n",
    "                    erosion = cv2.erode(dilation, kernel, iterations=2)\n",
    "                    out = pytesseract.image_to_string(erosion).strip()\n",
    "                    s += \" \" + out\n",
    "                dataframe_final.append(s)\n",
    "\n",
    "    arr = np.array(dataframe_final)\n",
    "    dataframe = pd.DataFrame(arr.reshape(len(rows), total_cells))\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def ocr_image_to_text(image_path, extracted_dir):\n",
    "    b_image, vertical_horizontal_lines = process_image(image_path)\n",
    "    boxes = extract_bounding_boxes(b_image, vertical_horizontal_lines)\n",
    "\n",
    "    if len(boxes) <= 1:\n",
    "        print(\"No Table Detected.\")\n",
    "        return  # No need to return the counter\n",
    "    else:\n",
    "        print('Table Extracted!')\n",
    "        dataframe = extract_text_from_boxes(b_image, boxes)\n",
    "        \n",
    "        # Changed this line to set output directory as the extracted_dir itself\n",
    "        output_dir = extracted_dir\n",
    "        \n",
    "        # Removed the redundant \"Cropped Images\" replacement\n",
    "        file_name_without_ext = os.path.basename(image_path).rsplit('.', 1)[0]\n",
    "        \n",
    "        csv_output_path = os.path.join(output_dir, f\"{file_name_without_ext}.csv\")\n",
    "        \n",
    "        dataframe.to_csv(csv_output_path, index=False, header=False)\n",
    "\n",
    "\n",
    "def process_images_in_extracted_dirs(main_wd, output_dir):\n",
    "    cropped_dirs = find_subdirs_with_name(main_wd, \"Cropped\")\n",
    "    for extracted_dir in cropped_dirs:\n",
    "        for image_path in find_image_files_in_dir(extracted_dir):\n",
    "            ocr_image_to_text(image_path, extracted_dir)\n",
    "\n",
    "\n",
    "## Use of Extractor\n",
    "main_wd = working_directory\n",
    "output_directory = os.path.dirname(main_wd)\n",
    "process_images_in_extracted_dirs(main_wd, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Perform Table Data Extraction Using Paddle OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PaddleOCR\n",
    "ocr = PaddleOCR(\n",
    "    use_gpu=True,\n",
    "    det_db_thresh=0.3,\n",
    "    det_db_box_thresh=0.5,\n",
    "    det_db_unclip_ratio=1.2\n",
    ")\n",
    "\n",
    "# Function to process the image\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "\n",
    "    img_bin = 255 - image\n",
    "    _, img_bin_otsu = cv2.threshold(img_bin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Vertical Line extraction\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, img_bin_otsu.shape[1] // 35))\n",
    "    eroded_image = cv2.erode(img_bin_otsu, vertical_kernel, iterations=1)\n",
    "    vertical_lines = cv2.dilate(eroded_image, vertical_kernel, iterations=1)\n",
    "\n",
    "    # Horizontal Line extraction\n",
    "    hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (np.array(img_bin_otsu).shape[1] // 50, 1))\n",
    "    image_2 = cv2.erode(img_bin_otsu, hor_kernel, iterations=1)\n",
    "    horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=2)\n",
    "\n",
    "    horizontal_contours, _ = cv2.findContours(horizontal_lines, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    vertical_contours, _ = cv2.findContours(vertical_lines, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    hor_lines = len(horizontal_contours)\n",
    "    ver_lines = len(vertical_contours)\n",
    "\n",
    "    if hor_lines > 1 or ver_lines > 1:\n",
    "\n",
    "        return image\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to plot bounding boxes on the original image\n",
    "def plot_boxes_on_original_image(img, bounding_boxes_list):\n",
    "    img_with_boxes = img.copy()\n",
    "\n",
    "    for bounding_boxes in bounding_boxes_list:\n",
    "        top_left = bounding_boxes[0]\n",
    "        bottom_right = bounding_boxes[2]\n",
    "\n",
    "        x1, y1 = top_left\n",
    "        x2, y2 = bottom_right\n",
    "\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(img_with_boxes, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "\n",
    "def extract_data_from_image(img_path, ocr_instance):\n",
    "\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    preprocessed_img = process_image(img_path)\n",
    "\n",
    "    \n",
    "    if preprocessed_img is None:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    else:  # Extract text using PaddleOCR\n",
    "        results = ocr_instance.ocr(preprocessed_img)\n",
    "        \n",
    "        # Process OCR results\n",
    "        result_list = [\n",
    "            [result[0][0], result[0][2], result[1][0], result[1][1]]\n",
    "            for result in results[0]\n",
    "        ]\n",
    "        \n",
    "        sorted_data = sorted(result_list, key=lambda x: x[0][1])\n",
    "        \n",
    "        # Group results by rows based on a threshold\n",
    "        threshold = 10\n",
    "        rows, current_row = [], []\n",
    "        for entry in sorted_data:\n",
    "            if not current_row or (entry[0][1] - current_row[-1][0][1] <= threshold):\n",
    "                current_row.append(entry)\n",
    "            else:\n",
    "                rows.append(current_row)\n",
    "                current_row = [entry]\n",
    "        \n",
    "        if current_row:\n",
    "            rows.append(current_row)\n",
    "        \n",
    "        # Sort and convert results to DataFrame\n",
    "        table = [sorted(row, key=lambda x: x[0][0]) for row in rows]\n",
    "        table_strings = [[entry[2] for entry in row] for row in table]\n",
    "        df = pd.DataFrame(table_strings)\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "def process_images_in_extracted_dirs(main_wd):\n",
    "    cropped_dirs = find_subdirs_with_name(main_wd, \"Cropped\")\n",
    "    for extracted_dir in cropped_dirs:\n",
    "        for image_path in find_image_files_in_dir(extracted_dir):\n",
    "            # Initialize PaddleOCR instance\n",
    "            ocr_instance = PaddleOCR(\n",
    "                use_gpu=True,\n",
    "                det_db_thresh=0.3,\n",
    "                det_db_box_thresh=0.5,\n",
    "                det_db_unclip_ratio=1.2\n",
    "            )\n",
    "            \n",
    "            # Extract data from image and save as DataFrame\n",
    "            df = extract_data_from_image(image_path, ocr_instance)\n",
    "\n",
    "            if df is None:\n",
    "                continue\n",
    "            else:\n",
    "                # Save the DataFrame to CSV in the same directory as the image\n",
    "                base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                output_file_path = os.path.join(os.path.dirname(image_path), base_filename + \".csv\")\n",
    "                df.to_csv(output_file_path, index=False, header=False)\n",
    "\n",
    "\n",
    "# Usage\n",
    "main_wd = working_directory\n",
    "output_directory = os.path.dirname(main_wd)\n",
    "process_images_in_extracted_dirs(main_wd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Perform Table Data Extraction Using Paddle OCR and Bounding Boxes from cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = PaddleOCR()\n",
    "\n",
    "\n",
    "def threshold_image(image):\n",
    "    \"\"\"Thresholds the image for further processing\"\"\"\n",
    "    img_bin = 255 - image\n",
    "    _, img_bin_otsu = cv2.threshold(img_bin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return img_bin_otsu\n",
    "\n",
    "def extract_lines(img_bin_otsu, orient=\"horizontal\"):\n",
    "    \"\"\"Extracts horizontal or vertical lines from a binarized image\"\"\"\n",
    "    if orient == \"horizontal\":\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (img_bin_otsu.shape[1] // 100, 1))\n",
    "    else:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, img_bin_otsu.shape[1] // 50))\n",
    "    eroded_image = cv2.erode(img_bin_otsu, kernel, iterations=1) \n",
    "    return cv2.dilate(eroded_image, kernel, iterations=1)\n",
    "\n",
    "def get_cell_locations(vertical_horizontal_lines):\n",
    "    \"\"\"Extracts cell locations from a combined vertical and horizontal lines image\"\"\"\n",
    "    contours, _ = cv2.findContours(vertical_horizontal_lines, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cell_locations = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > 20 and h > 20:\n",
    "            roi = vertical_horizontal_lines[y:y+h, x:x+w]\n",
    "            _, roi_bin = cv2.threshold(roi, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "            cell_contours, _ = cv2.findContours(roi_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for cell_contour in cell_contours:\n",
    "                cx, cy, cw, ch = cv2.boundingRect(cell_contour)\n",
    "                cell_locations.append((x + cx, y + cy, cw, ch))\n",
    "\n",
    "    return list(set(cell_locations))\n",
    "\n",
    "def process_cell_region(cell_region, ocr):\n",
    "    \"\"\"Processes a cell region using OCR and returns extracted text\"\"\"\n",
    "    results = ocr.ocr(cell_region)\n",
    "    text_list = [text_info[1][0] for entry in results if entry for text_info in entry]\n",
    "    return ' '.join(text_list) if text_list else '0'\n",
    "\n",
    "def detect_cells_in_image(image_path):\n",
    "    \"\"\"Main function to detect cells in the image\"\"\"\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    img_bin_otsu = threshold_image(image)\n",
    "    vertical_lines = extract_lines(img_bin_otsu, \"vertical\")\n",
    "    horizontal_lines = extract_lines(img_bin_otsu, \"horizontal\")\n",
    "    data_t = []\n",
    "\n",
    "    if vertical_lines.any() and horizontal_lines.any():\n",
    "        vertical_horizontal_lines = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "        vertical_horizontal_lines = cv2.dilate(vertical_horizontal_lines, kernel, iterations=5)\n",
    "        \n",
    "        cell_locations = get_cell_locations(vertical_horizontal_lines)\n",
    "\n",
    "        for cell in cell_locations:\n",
    "            x, y, w, h = cell\n",
    "            cell_region = image[y:y+h, x:x+w]\n",
    "            text = process_cell_region(cell_region, ocr)\n",
    "            data_t.append([text, [x, y]])\n",
    "\n",
    "        return data_t\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def bucket_data_by_rows(data, tolerance=12):\n",
    "    \"\"\"Group data into rows based on y-coordinates and a given tolerance.\"\"\"\n",
    "    rows_data = {}\n",
    "    for text, coord in data:\n",
    "        y = coord[1]\n",
    "        for key in sorted(rows_data.keys()):\n",
    "            if abs(y - key) <= tolerance:\n",
    "                rows_data[key].append((text, coord))\n",
    "                break\n",
    "        else:  # This else corresponds to the for-loop, and will only execute if the for-loop completes without a break\n",
    "            rows_data[y] = [(text, coord)]\n",
    "    return rows_data\n",
    "\n",
    "def convert_rows_to_dataframe(rows_data):\n",
    "    \"\"\"Convert organized rows data into a DataFrame.\"\"\"\n",
    "    header_row_coords = sorted(rows_data.keys())[0]\n",
    "    header_positions = [item[1][0] for item in rows_data[header_row_coords]]\n",
    "\n",
    "    df_data = []\n",
    "    for key in sorted(rows_data.keys()):\n",
    "        row_items = rows_data[key]\n",
    "        row_data = [''] * len(header_positions)\n",
    "        for text, coord in row_items:\n",
    "            closest_index = min(range(len(header_positions)), key=lambda i: abs(header_positions[i]-coord[0]))\n",
    "            row_data[closest_index] = text\n",
    "        df_data.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(df_data)\n",
    "\n",
    "def process_images_in_extracted_dirs(main_wd):\n",
    "    cropped_dirs = find_subdirs_with_name(main_wd, \"Cropped\")\n",
    "    for extracted_dir in cropped_dirs:\n",
    "        for image_path in find_image_files_in_dir(extracted_dir):\n",
    "            data = detect_cells_in_image(image_path)\n",
    "            if data:\n",
    "                data.sort(key=lambda x: (x[1][1], x[1][0]))\n",
    "                rows_data = bucket_data_by_rows(data)\n",
    "                df = convert_rows_to_dataframe(rows_data)\n",
    "                df = df.astype(str)\n",
    "                df = df.loc[:, df.iloc[0] != '0']\n",
    "                df.replace('', np.nan, inplace=True)\n",
    "                df.dropna(axis=1, how='all', inplace=True)\n",
    "                \n",
    "                # Save to csv\n",
    "                base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                output_file_path = os.path.join(os.path.dirname(image_path), base_filename + \".csv\")\n",
    "                df.to_csv(output_file_path, index=False, header=False)\n",
    "                \n",
    "\n",
    "# Usage\n",
    "process_images_in_extracted_dirs(working_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
